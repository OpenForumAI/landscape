{"items":[{"category":"Research","homepage_url":"https://www.cmu.edu/block-center/responsible-ai/index.html","id":"research--data--responsible-ai","logo":"logos/ef66c59356aca77521dc5751ad298391e54f4443c39b8d3d304fd15857fd3071.svg","name":"Responsible AI","subcategory":"Data","website":"https://www.cmu.edu/block-center/responsible-ai/index.html","description":"CMU's Responsible AI initiative brings together researchers and educators spanning computer science, engineering, decision sciences, philosophy, arts, economics, psychology, public policy, statistics, and business to make progress in:Translating research to policy and social impact: translating research insights into policy and positive social impact.Building community and serving our local and global communities: collaborating and co-designing with local communities and the public at large. Education and training: offering hands-on and experiential educational and research opportunities for students, staff and faculty. Partnerships: working collaboratively with partners to develop and deploy AI methodologies and tools that enable learning, practice, and research."},{"category":"Research","homepage_url":"https://www.trails.umd.edu/","id":"research--design-architecture--trails","logo":"logos/e315b2b77bc100ab04095cb1bfe1a5bcc2cf43014baafc77e61be8c45a7ad217.svg","name":"Trails","subcategory":"Design/architecture","website":"https://www.trails.umd.edu/","description":"The Design Decisions that Make LLM Development Projects Open, Secure, and Trustworthy. This project aims to operationalize principles of Trustworthy AI within the development of customized applications of open source Large Language Models (LLMs) with the goal of providing a pragmatic planning guide and toolkit for student/faculty project teams. This will be achieved through the practical examination of development processes utilized by student/faculty teams working on LLM-based projects (e.g., custom chatbot for a history course); with specific focus on student/faculty teams without Computer Science backgrounds. The project will utilize a combination of the NIST Trustworthy AI Risk Management framework [1], the CISA Secure by Design framework [2], and Open Source/Science principles [3, 4, 5] to guide these teams. The outcome will include the development of a consolidated framework and comprehensive toolkit (including a repository of best practices) aimed at enhancing the trustworthiness, security, and openness of AI applications in academic settings."},{"category":"Research","homepage_url":"https://www.cmu.edu/block-center/responsible-ai/index.html","id":"research--design-architecture--responsible-ai","logo":"logos/ef66c59356aca77521dc5751ad298391e54f4443c39b8d3d304fd15857fd3071.svg","name":"Responsible AI","subcategory":"Design/architecture","website":"https://www.cmu.edu/block-center/responsible-ai/index.html","description":"CMU's Responsible AI initiative brings together researchers and educators spanning computer science, engineering, decision sciences, philosophy, arts, economics, psychology, public policy, statistics, and business to make progress in: Translating research to policy and social impact: translating research insights into policy and positive social impact.Building community and serving our local and global communities: collaborating and co-designing with local communities and the public at large. Education and training: offering hands-on and experiential educational and research opportunities for students, staff and faculty. Partnerships: working collaboratively with partners to develop and deploy AI methodologies and tools that enable learning, practice, and research."},{"category":"Research","homepage_url":"https://drive.google.com/file/d/1fjjx4c2-wGTT3sdVwhgOsZ45OMbE44RY/view","id":"research--design-architecture--economic-impacts-of-ai-openness-regulation","logo":"logos/1ad01d5639bc7c16a0ec78b78e2aa8a0c360f643ea3169b137b46084903e856c.svg","name":"Economic Impacts of AI Openness Regulation","subcategory":"Design/architecture","website":"https://drive.google.com/file/d/1fjjx4c2-wGTT3sdVwhgOsZ45OMbE44RY/view","description":"Regulatory frameworks, such as the EU AI Act, encourage openness of general-purpose AI models by offering legal exemptions for 'open-source' models. Despite this legislative attention on openness, the definition of open-source foundation models remains ambiguous. This paper presents a stylized model of the regulator’s choice of an open-source definition to evaluate how AI openness standards will impact developers’ incentives."},{"category":"Research","homepage_url":"https://drive.google.com/file/d/1fjjx4c2-wGTT3sdVwhgOsZ45OMbE44RY/view","id":"research--code--economic-impacts-of-ai-openness-regulation","logo":"logos/1ad01d5639bc7c16a0ec78b78e2aa8a0c360f643ea3169b137b46084903e856c.svg","name":"Economic Impacts of AI Openness Regulation","subcategory":"Code","website":"https://drive.google.com/file/d/1fjjx4c2-wGTT3sdVwhgOsZ45OMbE44RY/view","description":"Regulatory frameworks, such as the EU AI Act, encourage openness of general-purpose AI models by offering legal exemptions for 'open-source' models. Despite this legislative attention on openness, the definition of open-source foundation models remains ambiguous. This paper presents a stylized model of the regulator’s choice of an open-source definition to evaluate how AI openness standards will impact developers’ incentives."}]}