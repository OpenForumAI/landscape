{"category":{"name":"Technical Prototypes","normalized_name":"technical-prototypes","subcategories":[{"name":"Data","normalized_name":"data"},{"name":"Design/architecture","normalized_name":"design-architecture"},{"name":"Code","normalized_name":"code"},{"name":"Compute","normalized_name":"compute"},{"name":"Model weights","normalized_name":"model-weights"},{"name":"Human feedback","normalized_name":"human-feedback"},{"name":"Evaluations","normalized_name":"evaluations"},{"name":"Intended vs unintended usage","normalized_name":"intended-vs-unintended-usage"},{"name":"Expertise, education, training","normalized_name":"expertise-education--training"},{"name":"Oversight","normalized_name":"oversight"},{"name":"Other","normalized_name":"other"}]},"foundation":"OFAI","items":[{"category":"Technical Prototypes","id":"technical-prototypes--data--wikibench","name":"Wikibench","logo":"logos/fe03f6772fddb67d262845d666d586dd4e51747af33e345764e892975873e80a.svg","subcategory":"Data","website":"https://www.hcii.cmu.edu/research/human-centered-ai","description":"Wikibench provides tools for AI deployed in community contexts, addressing the limitations of datasets created without community input.","maturity":"graduated"},{"category":"Technical Prototypes","id":"technical-prototypes--data--connected-experience-lab-coex-lab","name":"Connected Experience Lab (CoEx Lab)","logo":"logos/fe03f6772fddb67d262845d666d586dd4e51747af33e345764e892975873e80a.svg","subcategory":"Data","website":"https://coexlab.com","description":"Focused on designing interactive systems to empower users to communicate and analyze data more effectively.","maturity":"graduated"},{"category":"Technical Prototypes","id":"technical-prototypes--design-architecture--jigsaw-supporting-designers-to-prototype-multimodal-applications","name":"Jigsaw: Supporting Designers to Prototype Multimodal Applications","logo":"logos/fe03f6772fddb67d262845d666d586dd4e51747af33e345764e892975873e80a.svg","subcategory":"Design/architecture","website":"https://www.hcii.cmu.edu/research/human-centered-ai","description":"TThis project helps designers assemble AI models for multimodal applications, enabling them to combine language, vision, and other modalities."},{"category":"Technical Prototypes","id":"technical-prototypes--human-feedback--voice-pilot-framework","name":"Voice Pilot Framework","logo":"logos/fe03f6772fddb67d262845d666d586dd4e51747af33e345764e892975873e80a.svg","subcategory":"Human feedback","website":"https://www.cmu.edu/news/stories/archives/2024/august/voicepilot-framework-enhances-communication-between-humans-and-physically-assistive-robots","description":"The VoicePilot project at Carnegie Mellon University develops a speech interface for physically assistive robots, enhancing communication through large language models (LLMs). The framework enables personalized and robust voice commands, improving care for individuals with motor impairments. Tested on the Obi assistive feeding robot, the study established five guidelines for effective speech integration in assistive technology."},{"category":"Technical Prototypes","id":"technical-prototypes--human-feedback--eye-into-ai","name":"Eye into AI","logo":"logos/fe03f6772fddb67d262845d666d586dd4e51747af33e345764e892975873e80a.svg","subcategory":"Human feedback","website":"https://www.hcii.cmu.edu/research/human-centered-ai","description":"A novel approach using games to evaluate explainable AI (XAI) techniques by gathering human feedback on model transparency."},{"category":"Technical Prototypes","id":"technical-prototypes--human-feedback--future-interfaces-group-fig","name":"Future Interfaces Group (FIG)","logo":"logos/fe03f6772fddb67d262845d666d586dd4e51747af33e345764e892975873e80a.svg","subcategory":"Human feedback","website":"http://figlab.com","description":"FIG creates new interface technologies for immersive environments, including wearables and smart environments."},{"category":"Technical Prototypes","id":"technical-prototypes--intended-vs-unintended-usage--predicting-and-visualizing-overdose-risk-for-public-health","name":"Predicting and Visualizing Overdose Risk for Public Health","logo":"logos/fe03f6772fddb67d262845d666d586dd4e51747af33e345764e892975873e80a.svg","subcategory":"Intended vs unintended usage","website":"https://www.hcii.cmu.edu/research/human-centered-ai","description":"This project uses machine learning to predict opioid overdose risks, aiding public health efforts with data visualization tools."},{"category":"Technical Prototypes","id":"technical-prototypes--other--d-form-and-d-stable-labs","name":"d.form and d.stable Labs","logo":"logos/fe03f6772fddb67d262845d666d586dd4e51747af33e345764e892975873e80a.svg","subcategory":"Other","website":"https://www.hcii.cmu.edu/research/human-centered-ai","description":"This lab explores human-AI interaction by developing prototypes for emerging technologies like smart environments and robots."}]}