{"category":{"name":"Research","normalized_name":"research","subcategories":[{"name":"Design/architecture","normalized_name":"design-architecture"}]},"foundation":"OFAI","items":[{"category":"Research","id":"research--design-architecture--trails","name":"Trails","logo":"logos/e315b2b77bc100ab04095cb1bfe1a5bcc2cf43014baafc77e61be8c45a7ad217.svg","subcategory":"Design/architecture","website":"https://www.trails.umd.edu/","description":"The Design Decisions that Make LLM Development Projects Open, Secure, and Trustworthy. This project aims to operationalize principles of Trustworthy AI within the development of customized applications of open source Large Language Models (LLMs) with the goal of providing a pragmatic planning guide and toolkit for student/faculty project teams. This will be achieved through the practical examination of development processes utilized by student/faculty teams working on LLM-based projects (e.g., custom chatbot for a history course); with specific focus on student/faculty teams without Computer Science backgrounds. The project will utilize a combination of the NIST Trustworthy AI Risk Management framework [1], the CISA Secure by Design framework [2], and Open Source/Science principles [3, 4, 5] to guide these teams. The outcome will include the development of a consolidated framework and comprehensive toolkit (including a repository of best practices) aimed at enhancing the trustworthiness, security, and openness of AI applications in academic settings."}]}