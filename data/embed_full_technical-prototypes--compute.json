{"items":[{"category":"Technical Prototypes","homepage_url":"https://github.com/georgia-tech-db/evadb","id":"technical-prototypes--compute--eva-db","logo":"logos/a1c5c5ab14758d4cc263242f1971fe9fcab344838caae828707e62c8460d0232.svg","name":"Eva DB","subcategory":"Compute","website":"https://github.com/georgia-tech-db/evadb","description":"Tool to use SQL and database semantics to create AI systems"},{"category":"Technical Prototypes","homepage_url":"https://github.com/GATECH-EIC/Linearized-LLM","id":"technical-prototypes--compute--linearized-llm","logo":"logos/88dc774ecd0fdee2268057dffe2a9ad9093dbc422c2783d7705eefbb8d2e3959.svg","name":"Linearized LLM","subcategory":"Compute","website":"https://github.com/GATECH-EIC/Linearized-LLM","description":"ICML 2024 related work focused on improving Llama2 speed and perplexity. When Linear Attention Meets Autoregressive Decoding: Towards More Effective and Efficient Linearized Large Language Models"}]}