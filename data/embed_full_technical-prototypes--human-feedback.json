{"items":[{"category":"Technical Prototypes","homepage_url":"https://www.cmu.edu/news/stories/archives/2024/august/voicepilot-framework-enhances-communication-between-humans-and-physically-assistive-robots","id":"technical-prototypes--human-feedback--voice-pilot-framework","logo":"logos/fe03f6772fddb67d262845d666d586dd4e51747af33e345764e892975873e80a.svg","name":"Voice Pilot Framework","subcategory":"Human feedback","website":"https://www.cmu.edu/news/stories/archives/2024/august/voicepilot-framework-enhances-communication-between-humans-and-physically-assistive-robots","description":"The VoicePilot project at Carnegie Mellon University develops a speech interface for physically assistive robots, enhancing communication through large language models (LLMs). The framework enables personalized and robust voice commands, improving care for individuals with motor impairments. Tested on the Obi assistive feeding robot, the study established five guidelines for effective speech integration in assistive technology."},{"category":"Technical Prototypes","homepage_url":"https://www.hcii.cmu.edu/research/human-centered-ai","id":"technical-prototypes--human-feedback--eye-into-ai","logo":"logos/fe03f6772fddb67d262845d666d586dd4e51747af33e345764e892975873e80a.svg","name":"Eye into AI","subcategory":"Human feedback","website":"https://www.hcii.cmu.edu/research/human-centered-ai","description":"A novel approach using games to evaluate explainable AI (XAI) techniques by gathering human feedback on model transparency."},{"category":"Technical Prototypes","homepage_url":"http://figlab.com","id":"technical-prototypes--human-feedback--future-interfaces-group-fig","logo":"logos/fe03f6772fddb67d262845d666d586dd4e51747af33e345764e892975873e80a.svg","name":"Future Interfaces Group (FIG)","subcategory":"Human feedback","website":"http://figlab.com","description":"FIG creates new interface technologies for immersive environments, including wearables and smart environments."}]}