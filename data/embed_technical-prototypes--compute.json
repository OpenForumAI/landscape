{"category":{"name":"Technical Prototypes","normalized_name":"technical-prototypes","subcategories":[{"name":"Compute","normalized_name":"compute"}]},"foundation":"OFAI","items":[{"category":"Technical Prototypes","id":"technical-prototypes--compute--eva-db","name":"Eva DB","logo":"logos/a1c5c5ab14758d4cc263242f1971fe9fcab344838caae828707e62c8460d0232.svg","subcategory":"Compute","website":"https://github.com/georgia-tech-db/evadb","description":"Tool to use SQL and database semantics to create AI systems"},{"category":"Technical Prototypes","id":"technical-prototypes--compute--linearized-llm","name":"Linearized LLM","logo":"logos/88dc774ecd0fdee2268057dffe2a9ad9093dbc422c2783d7705eefbb8d2e3959.svg","subcategory":"Compute","website":"https://github.com/GATECH-EIC/Linearized-LLM","description":"ICML 2024 related work focused on improving Llama2 speed and perplexity. When Linear Attention Meets Autoregressive Decoding: Towards More Effective and Efficient Linearized Large Language Models"}]}