[{"category":"Technical Prototypes","homepage_url":"https://github.com/georgia-tech-db/evadb","id":"technical-prototypes--compute--eva-db","logo_url":"http://127.0.0.1:8000/logos/38b2ae554053c22c454584e9d6c5c94d9ce2ca2e22244c1f06de89e7c4956b57.svg","name":"Eva DB","subcategory":"Compute","description":"Tool to use SQL and database semantics to create AI systems"},{"category":"Technical Prototypes","homepage_url":"https://github.com/GATECH-EIC/Linearized-LLM","id":"technical-prototypes--compute--linearized-llm","logo_url":"http://127.0.0.1:8000/logos/e39ad5ad12a68446946fd8f8181cc0cd6dd9cae71dff69919e4a69e1baf8a86b.svg","name":"Linearized LLM","subcategory":"Compute","description":"ICML 2024 related work focused on improving Llama2 speed and perplexity. When Linear Attention Meets Autoregressive Decoding: Towards More Effective and Efficient Linearized Large Language Models"}]