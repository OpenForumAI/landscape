[{"category":"Technical Prototypes","homepage_url":"https://github.com/georgia-tech-db/evadb","id":"technical-prototypes--compute--eva-db","logo_url":"http://127.0.0.1:8000/logos/38b2ae554053c22c454584e9d6c5c94d9ce2ca2e22244c1f06de89e7c4956b57.svg","name":"Eva DB","subcategory":"Compute","description":"Tool to use SQL and database semantics to create AI systems"},{"category":"Technical Prototypes","homepage_url":"https://www.geoelements.org/gns/#/","id":"technical-prototypes--compute--graph-network-simulator","logo_url":"http://127.0.0.1:8000/","name":"Graph Network Simulator","subcategory":"Compute","description":"Graph Network-based Simulator (GNS) is a framework for developing generalizable, efficient, and accurate machine learning (ML)-based surrogate models for particulate and fluid systems using Graph Neural Networks (GNNs). GNS code is a viable surrogate for numerical methods such as Material Point Method, Smooth Particle Hydrodynamics and Computational Fluid dynamics. GNS exploits distributed data parallelism to achieve fast multi-GPU training. The GNS code can handle complex boundary conditions and multi-material interactions. GNS is a viable surrogate for numerical models such as Material Point Method, Smooth Particle Hydrodynamics and Computational Fluid dynamics."},{"category":"Technical Prototypes","homepage_url":"https://github.com/GATECH-EIC/Linearized-LLM","id":"technical-prototypes--compute--linearized-llm","logo_url":"http://127.0.0.1:8000/logos/e39ad5ad12a68446946fd8f8181cc0cd6dd9cae71dff69919e4a69e1baf8a86b.svg","name":"Linearized LLM","subcategory":"Compute","description":"ICML 2024 related work focused on improving Llama2 speed and perplexity. When Linear Attention Meets Autoregressive Decoding: Towards More Effective and Efficient Linearized Large Language Models"},{"category":"Technical Prototypes","homepage_url":"https://tyler-ingebrand.github.io/OperatorFunctionEncoder/","id":"technical-prototypes--compute--operator-learning","logo_url":"http://127.0.0.1:8000/","name":"Operator Learning","subcategory":"Compute","description":"We present Basis-to-Basis (B2B) operator learning, a novel approach for learning operators on Hilbert spaces of functions based on the foundational ideas of function encoders. We decompose the task of learning operators into two parts: learning sets of basis functions for both the input and output spaces, and learning a potentially nonlinear mapping between the coefficients of the basis functions. B2B operator learning circumvents many challenges of prior works, such as requiring data to be at fixed locations, by leveraging classic techniques such as least-squares to compute the coefficients."}]